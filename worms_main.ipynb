{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "id": "initial_id",
    "outputId": "cf09db59-cbf1-4681-83f0-85b51644e10a",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting torch-geometric\n",
      "  Downloading torch_geometric-2.4.0-py3-none-any.whl (1.0 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.0/1.0 MB\u001B[0m \u001B[31m5.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.66.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.23.5)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.11.4)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.31.0)\n",
      "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.1)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.2.2)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (2.1.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2023.11.17)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (3.2.0)\n",
      "Installing collected packages: torch-geometric\n",
      "Successfully installed torch-geometric-2.4.0\n"
     ]
    }
   ],
   "source": [
    "from typing import Any\n",
    "\n",
    "from lightning.pytorch.utilities.types import STEP_OUTPUT\n",
    "!pip install torch-geometric"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch_geometric.data import Data\n",
    "import lightning as L\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import wandb as wndb\n",
    "from torch_geometric.nn import GATConv"
   ],
   "metadata": {
    "id": "TBf6OzRISHY3"
   },
   "id": "TBf6OzRISHY3",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "class WormUpExamplesDataset(Dataset):\n",
    "\n",
    "  def __init__(self, graphs: list[Data], actions: list[int], rewards: list[int]):\n",
    "    self.data = zip(graphs, actions, rewards)\n",
    "    \n",
    "    \n",
    "  def __getitem__(self, idx: int):\n",
    "    return self.data[idx]\n",
    "  \n",
    "  def __len__(self):\n",
    "    return len(self.data)\n",
    "  \n",
    "  def collate(self,data: list):\n",
    "    graphs = []\n",
    "    actions = []\n",
    "    rewards = []\n",
    "    for el in data:\n",
    "      graphs.append(el[0])\n",
    "      actions.append(el[1])\n",
    "      rewards.append(el[2])\n",
    "    return graphs,actions, rewards\n",
    "  \n",
    "  def get_dataloader(self, batch_size: int, shuffle: bool = False):\n",
    "    return DataLoader(self, batch_size=batch_size, shuffle=shuffle, collate_fn=self.collate)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "id": "RGjiW4gISNyY"
   },
   "id": "RGjiW4gISNyY",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class ModuleCallback(L.Callback):\n",
    "\n",
    "  def on_train_epoch_end(self, trainer, pl_module):\n",
    "\n",
    "      epoch_mean = float(torch.stack(pl_module.train_loss).mean())\n",
    "      print(\"training_epoch_mean loss = \", epoch_mean)\n",
    "      wndb.log({\"train_loss\": epoch_mean})\n",
    "      # free up the memory\n",
    "      pl_module.train_loss.clear()\n",
    "\n",
    "  def on_validation_epoch_end(self,trainer, pl_module):\n",
    "\n",
    "    mean_loss = float(torch.stack(pl_module.val_loss).mean())\n",
    "    mean_f1 = float(torch.stack(pl_module.f1_score).mean())\n",
    "    mean_acc = float(torch.stack(pl_module.acc).mean())\n",
    "    mean_prec = float(torch.stack(pl_module.prec).mean())\n",
    "    mean_rec = float(torch.stack(pl_module.rec).mean())\n",
    "\n",
    "    print(\"val_loss = \", mean_loss)\n",
    "    print(\"f1 = \", mean_f1)\n",
    "    print(\"acc = \", mean_acc)\n",
    "    print(\"prec = \", mean_prec)\n",
    "    print(\"rec = \", mean_rec)\n",
    "    wndb.log({\"val_loss\": mean_loss, \"f1\": mean_f1, \"acc\": mean_acc, \"prec\": mean_prec, \"rec\": mean_rec })\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dcd567e72bf3219b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class GraphNN(nn.Module):\n",
    "\n",
    "  def __init__(self,in_size, out_size, h_size, deep,activation,device):\n",
    "    super(GraphNN, self).__init__()\n",
    "    self.activation = activation\n",
    "    if deep == 1:\n",
    "      self.layers = [GATConv(in_size,out_size).to(device)]\n",
    "    else:\n",
    "      self.layers = [GATConv(in_size,h_size).to(device)]\n",
    "      for _ in range(deep-2):\n",
    "        self.layers.append(GATConv(h_size,h_size).to(device))\n",
    "      self.layers.append(GATConv(h_size,out_size).to(device))\n",
    "\n",
    "\n",
    "  def forward(self,data):\n",
    "    edge_index = data.edge_index\n",
    "    edge_attr = data.edge_attr\n",
    "    x = data.x\n",
    "    for layer in self.layers[:-1]:\n",
    "      x = self.activation(layer(x, edge_index, edge_attr))\n",
    "\n",
    "    return self.layers[-1](x, edge_index, edge_attr)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a7077f94db9f1513"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class LinearNN(nn.Module):\n",
    "  def __init__(self,in_size, out_size, h_size, deep,activation):\n",
    "    super(LinearNN, self).__init__()\n",
    "    if deep == 1:\n",
    "      layers = [nn.Linear(in_size,out_size), activation]\n",
    "    else:\n",
    "      layers = [nn.Linear(in_size,h_size), activation]\n",
    "      for _ in range(deep-2):\n",
    "        layers.append(nn.Linear(h_size,h_size))\n",
    "        layers.append(activation)\n",
    "      layers.append(nn.Linear(h_size,out_size))\n",
    "    self.linear = nn.Sequential(*layers)\n",
    "\n",
    "  def forward(self,data):\n",
    "    return self.linear(data)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2e04dccdc0f056e0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "class WormModule(L.LightningModule):\n",
    "  \n",
    "  def __int__(self, linear: nn.Module, gnn: nn.Module, lr: float = 1e-3):\n",
    "    self.encoder = gnn\n",
    "    self.decoder = linear\n",
    "      \n",
    "  def forward(self, data):\n",
    "    actions = data[1]\n",
    "    graphs = data[0] \n",
    "    embeddings = []\n",
    "    for i in range(len(graphs)):\n",
    "      g = graphs[i]\n",
    "      x = self.encoder(g.x, g.edge_index)\n",
    "      embeddings.append(x[actions[i]])\n",
    "    embeddings = torch.tensor(embeddings, dtype=torch.float)\n",
    "    return self.decoder(embeddings)\n",
    "      \n",
    "        \n",
    "  def training_step(self, batch, batch_idx):\n",
    "    \n",
    "    \n",
    "    \n",
    "  def validation_step(self, batch, batch_idx):\n",
    "    \n",
    "    \n",
    "  def configure_optimizers(self):\n",
    "      optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "      return optimizer\n",
    "    \n",
    "  "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "19fe1a895b6ecda6"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "provenance": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
