{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **SETUP**"
      ],
      "metadata": {
        "id": "JlXSQpAMME6g"
      },
      "id": "JlXSQpAMME6g"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "initial_id",
      "metadata": {
        "collapsed": true,
        "id": "initial_id",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9e53c2c-ca92-4dae-d64f-efba74538360"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch-geometric in /usr/local/lib/python3.10/dist-packages (2.4.0)\n",
            "Requirement already satisfied: lightning in /usr/local/lib/python3.10/dist-packages (2.2.0)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.16.3)\n",
            "Requirement already satisfied: gymnasium in /usr/local/lib/python3.10/dist-packages (0.29.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.66.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.11.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.31.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.4.0)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: PyYAML<8.0,>=5.4 in /usr/local/lib/python3.10/dist-packages (from lightning) (6.0.1)\n",
            "Requirement already satisfied: fsspec[http]<2025.0,>=2022.5.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (2023.6.0)\n",
            "Requirement already satisfied: lightning-utilities<2.0,>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (0.10.1)\n",
            "Requirement already satisfied: packaging<25.0,>=20.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (23.2)\n",
            "Requirement already satisfied: torch<4.0,>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (2.1.0+cu121)\n",
            "Requirement already satisfied: torchmetrics<3.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (1.3.0.post0)\n",
            "Requirement already satisfied: typing-extensions<6.0,>=4.4.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (4.9.0)\n",
            "Requirement already satisfied: pytorch-lightning in /usr/local/lib/python3.10/dist-packages (from lightning) (2.2.0)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.41)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.40.3)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (2.2.1)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (0.0.4)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<2025.0,>=2022.5.0->lightning) (3.9.3)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2024.2.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch<4.0,>=1.13.0->lightning) (3.13.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch<4.0,>=1.13.0->lightning) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch<4.0,>=1.13.0->lightning) (3.2.1)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch<4.0,>=1.13.0->lightning) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (2.1.5)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (3.2.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning) (4.0.3)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch<4.0,>=1.13.0->lightning) (1.3.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.4.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.2.0)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!pip install torch-geometric lightning wandb gymnasium\n",
        "!pip install -U scikit-learn\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch_geometric.data import Data\n",
        "import lightning as L\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import wandb as wndb\n",
        "from torch_geometric.nn import GATConv\n",
        "from sklearn.metrics import r2_score, mean_absolute_error, root_mean_squared_error\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from lightning.pytorch.callbacks import ModelCheckpoint\n",
        "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
        "import gymnasium as gym\n",
        "from gymnasium.envs.registration import register\n",
        "import pdb"
      ],
      "metadata": {
        "id": "TBf6OzRISHY3"
      },
      "id": "TBf6OzRISHY3",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **MODEL AND RELATED STUFF**"
      ],
      "metadata": {
        "collapsed": false,
        "id": "4bf1f40cd3ec9c0"
      },
      "id": "4bf1f40cd3ec9c0"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "outputs": [],
      "source": [
        "class GreedyWorm(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(GreedyWorm, self).__init__()\n",
        "\n",
        "    def forward(self, data):\n",
        "        graphs, positions = data\n",
        "        return [graphs[i].x[positions[i]] for i in range(len(positions))]\n",
        ""
      ],
      "metadata": {
        "id": "2a703591e88d0fae"
      },
      "id": "2a703591e88d0fae"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class WormUpExamplesDataset(Dataset):\n",
        "\n",
        "    def __init__(self, graphs: list[Data], actions: list[int], rewards: list[int]):\n",
        "        self.data = zip(graphs, actions, rewards)\n",
        "\n",
        "    def __getitem__(self, idx: int):\n",
        "        return self.data[idx]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def collate(self, data: list):\n",
        "        graphs = []\n",
        "        actions = []\n",
        "        rewards = []\n",
        "        for el in data:\n",
        "            graphs.append(el[0])\n",
        "            actions.append(el[1])\n",
        "            rewards.append(el[2])\n",
        "        return graphs, actions, rewards\n",
        "\n",
        "    def get_dataloader(self, batch_size: int, shuffle: bool = False):\n",
        "        return DataLoader(self, batch_size=batch_size, shuffle=shuffle, collate_fn=self.collate)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "RGjiW4gISNyY"
      },
      "id": "RGjiW4gISNyY",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "outputs": [],
      "source": [
        "class GraphNN(nn.Module):\n",
        "\n",
        "    def __init__(self, in_size, out_size, h_size, deep, activation, device=\"cpu\"):\n",
        "        super(GraphNN, self).__init__()\n",
        "        self.activation = activation\n",
        "        if deep == 1:\n",
        "            self.layers = [GATConv(in_size, out_size)]  #.to(device)]\n",
        "        else:\n",
        "            self.layers = [GATConv(in_size, h_size)]  #.to(device)]\n",
        "            for _ in range(deep - 2):\n",
        "                self.layers.append(GATConv(h_size, h_size))  #.to(device))\n",
        "            self.layers.append(GATConv(h_size, out_size))  #.to(device))\n",
        "\n",
        "    def forward(self, data):\n",
        "        edge_index = data.edge_index\n",
        "        edge_attr = data.edge_attr\n",
        "        x = data.x\n",
        "        for layer in self.layers[:-1]:\n",
        "            x = self.activation(layer(x, edge_index, edge_attr))\n",
        "\n",
        "        return self.layers[-1](x, edge_index, edge_attr)\n",
        "\n"
      ],
      "metadata": {
        "id": "a7077f94db9f1513"
      },
      "id": "a7077f94db9f1513"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "outputs": [],
      "source": [
        "class LinearNN(nn.Module):\n",
        "    def __init__(self, in_size, out_size, h_size, deep, activation):\n",
        "        super(LinearNN, self).__init__()\n",
        "        if deep == 1:\n",
        "            layers = [nn.Linear(in_size, out_size), activation]\n",
        "        else:\n",
        "            layers = [nn.Linear(in_size, h_size), activation]\n",
        "            for _ in range(deep - 2):\n",
        "                layers.append(nn.Linear(h_size, h_size))\n",
        "                layers.append(activation)\n",
        "            layers.append(nn.Linear(h_size, out_size))\n",
        "        self.linear = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, data):\n",
        "        return self.linear(data)"
      ],
      "metadata": {
        "id": "2e04dccdc0f056e0"
      },
      "id": "2e04dccdc0f056e0"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "outputs": [],
      "source": [
        "\n",
        "class IntelligentWorm(L.LightningModule):\n",
        "\n",
        "    def __init__(self, linear: nn.Module, gnn: nn.Module, lr: float = 1e-3):\n",
        "        super(IntelligentWorm, self).__init__()\n",
        "        self.encoder = gnn\n",
        "        self.decoder = linear\n",
        "        self.loss = nn.MSELoss()\n",
        "        self.validation_predictions = []\n",
        "        self.validation_targets = []\n",
        "        self.validation_loss = []\n",
        "        self.train_loss = []\n",
        "        self.best_val_loss = 100000000\n",
        "        self.best_mae = 100000000\n",
        "        self.best_rmse = 1000000000\n",
        "        self.best_r2 = -1\n",
        "        self.best_model = 0\n",
        "        self.lr = lr\n",
        "\n",
        "    def update_best_stats(self, val_loss, mae, rmse, r2):\n",
        "        self.best_val_loss = val_loss\n",
        "        self.best_mae = mae\n",
        "        self.best_rmse = rmse\n",
        "        self.best_r2 = r2\n",
        "\n",
        "    def forward(self, data):\n",
        "        actions = data[1]\n",
        "        graphs = data[0]\n",
        "        embeddings = []\n",
        "        for i in range(len(graphs)):\n",
        "            g = graphs[i]\n",
        "            x = self.encoder(g.x, g.edge_index)\n",
        "            embeddings.append(x[actions[i]])\n",
        "        embeddings = torch.tensor(embeddings, dtype=torch.float)\n",
        "        return self.decoder(embeddings)\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        graphs, actions, rewards = batch\n",
        "        predictions = self.forward((graphs, actions))\n",
        "        train_loss = self.loss(predictions, rewards)\n",
        "        self.train_loss.append(train_loss)\n",
        "\n",
        "        return train_loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        graphs, actions, rewards = batch\n",
        "        self.validation_targets.append(rewards)\n",
        "        predictions = self.forward((graphs, actions))\n",
        "        validation_loss = self.loss(predictions, rewards)\n",
        "        self.validation_predictions.append(predictions)\n",
        "        self.validation_loss.append(validation_loss)\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)\n",
        "        return optimizer\n",
        "\n"
      ],
      "metadata": {
        "id": "19fe1a895b6ecda6"
      },
      "id": "19fe1a895b6ecda6"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "outputs": [],
      "source": [
        "class WormCallback(L.Callback):\n",
        "\n",
        "    def on_train_epoch_end(self, trainer, pl_module):\n",
        "\n",
        "        epoch_mean = float(torch.stack(pl_module.train_loss).mean())\n",
        "        print(\"training_epoch_mean loss = \", epoch_mean)\n",
        "        # free up the memory\n",
        "        pl_module.train_loss.clear()\n",
        "        try:\n",
        "            wndb.log({\"train_loss\": epoch_mean})\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "    def on_validation_epoch_end(self, trainer, pl_module: IntelligentWorm):\n",
        "        r2 = r2_score(pl_module.validation_predictions, pl_module.validation_targets)\n",
        "        mae = mean_absolute_error(pl_module.validation_predictions, pl_module.validation_targets)\n",
        "        rmse = root_mean_squared_error(pl_module.validation_predictions, pl_module.validation_targets)\n",
        "        pl_module.validation_loss.clear()\n",
        "        pl_module.validation_predictions.clear()\n",
        "        pl_module.validation_targets.clear()\n",
        "\n",
        "        mean_loss = float(torch.stack(pl_module.validation_loss).mean())\n",
        "\n",
        "        print(\"val_loss = \", mean_loss)\n",
        "        print(\"mean_absolute_error = \", mae)\n",
        "        print(\"root_mean_squared_error = \", rmse)\n",
        "        print(\"r2 = \", r2)\n",
        "        count = 0\n",
        "        count += 1 if mean_loss < pl_module.best_val_loss else 0\n",
        "        count += 1 if mae < pl_module.best_mae else 0\n",
        "        count += 1 if rmse < pl_module.best_rmse else 0\n",
        "        count += 1 if r2 > pl_module.best_r2 else 0\n",
        "        if count >= 3 or count == 2 and mean_loss < pl_module.best_val_loss:\n",
        "            pl_module.update_best_stats(mean_loss, mae, rmse, r2)\n",
        "            pl_module.best_model -= 1\n",
        "            pl_module.log(\"best_model\", pl_module.best_model)\n",
        "        else:\n",
        "            pl_module.log(\"best_model\", pl_module.best_model + 1)\n",
        "\n",
        "        try:\n",
        "            wndb.log({\"val_loss\": mean_loss, \"mean_absolute_error\": mae, \"root_mean_squared_error\": rmse, \"r2\": r2})\n",
        "        except:\n",
        "            pass\n",
        "\n"
      ],
      "metadata": {
        "id": "dcd567e72bf3219b"
      },
      "id": "dcd567e72bf3219b"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **AGENT**"
      ],
      "metadata": {
        "id": "zeEN5X3hOH3D"
      },
      "id": "zeEN5X3hOH3D"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "class WormsMasterAgent:\n",
        "\n",
        "    def __init__(\n",
        "            self,\n",
        "            model,\n",
        "            initial_epsilon: float,\n",
        "            epsilon_decay: float,\n",
        "            final_epsilon: float,\n",
        "            learning_rate: float = 1,\n",
        "            discount_factor: float = 0.95,\n",
        "            decay_after: int = 1,\n",
        "            #trainer params\n",
        "            batch_size: int = 32,\n",
        "            episodes_for_batch: int = 20,\n",
        "            trainer_deterministic: bool = True,\n",
        "            trainer_max_epochs: int = 20,\n",
        "            trainer_accelerator: str = \"cpu\"\n",
        "\n",
        "    ):\n",
        "        self.batch_size = batch_size\n",
        "        self.episodes_for_batch = episodes_for_batch\n",
        "        self.episode = 0\n",
        "        self.learning_model = model\n",
        "        self.model = GreedyWorm()\n",
        "        self.lr = learning_rate\n",
        "        self.discount_factor = discount_factor\n",
        "        self.epsilon = initial_epsilon\n",
        "        self.epsilon_decay = epsilon_decay\n",
        "        self.final_epsilon = final_epsilon\n",
        "        self.decay_after = decay_after\n",
        "        self.checkpoint_callback = ModelCheckpoint(dirpath=\"Model/\", filename=\"worms_model.ckpt\", save_top_k=1,\n",
        "                                                   mode='min', monitor='best_model')\n",
        "        self.worm_callback = WormCallback()\n",
        "        self.early_stopping_callback = EarlyStopping(monitor='best_model', mode='min', patience=3)\n",
        "        self.trainer = L.Trainer(deterministic=trainer_deterministic,\n",
        "                                 max_epochs=trainer_max_epochs, accelerator=trainer_accelerator,\n",
        "                                 callbacks=[self.checkpoint_callback, self.worm_callback, self.early_stopping_callback])\n",
        "        self.actual_rewards = np.array([])\n",
        "        self.actual_observations = []\n",
        "        self.actual_actions = []\n",
        "        self.model_training_data = {\n",
        "            \"actions\": [],\n",
        "            \"observations\": [],\n",
        "            \"rewards\": []\n",
        "        }\n",
        "\n",
        "    def get_action(self, observation, available_actions: list[int]) -> int:\n",
        "        graph = observation[\"field\"]\n",
        "        worms = observation[\"worms\"]\n",
        "\n",
        "        self.actual_rewards = np.append(self.actual_rewards, 0)\n",
        "        # with probability epsilon return a random action to explore the environment\n",
        "        if np.random.random() < self.epsilon:\n",
        "            i = np.random.randint(0, high=len(available_actions))\n",
        "            return available_actions[i]\n",
        "\n",
        "        # with probability (1 - epsilon) act greedily (exploit)\n",
        "        else:\n",
        "            self.model.eval()\n",
        "            with torch.no_grad():\n",
        "                return np.argmax(self.model(([graph] * len(available_actions), available_actions)))\n",
        "\n",
        "    def update(self, observation, action: int, reward: int, terminated: bool):\n",
        "        #breakpoint()\n",
        "        graph = observation[\"field\"]\n",
        "        worms = observation[\"worms\"]\n",
        "        self.actual_observations.append(graph)\n",
        "        self.actual_actions.append(action)\n",
        "        self.actual_rewards += self.lr * reward\n",
        "\n",
        "        if terminated:\n",
        "\n",
        "            print(f\"total reward = {self.actual_rewards[0]}, actions list = {self.actual_actions}\")\n",
        "            self.episode += 1\n",
        "            self.model_training_data[\"actions\"] += self.actual_actions.copy()\n",
        "            self.actual_actions = []\n",
        "            self.model_training_data[\"observations\"] += self.actual_observations.copy()\n",
        "            self.actual_observations = []\n",
        "            self.model_training_data[\"rewards\"] += self.actual_rewards.tolist()\n",
        "            self.actual_rewards = np.array([])\n",
        "            if self.episode % self.decay_after == 0:\n",
        "                self.decay_epsilon()\n",
        "            print(f\"starting episode {self.episode}, epsilon = {self.epsilon}\")\n",
        "            if self.episode % self.episodes_for_batch == 0:\n",
        "                self.train_model()\n",
        "                self.model = self.learning_model\n",
        "\n",
        "    def decay_epsilon(self):\n",
        "        self.epsilon = max(self.final_epsilon, self.epsilon - self.epsilon_decay)\n",
        "\n",
        "    def prepare_data(self):\n",
        "        #breakpoint()\n",
        "        print(\"preparing data to train\")\n",
        "        x = list(zip(self.model_training_data[\"observations\"], self.model_training_data[\"actions\"]))\n",
        "        y = self.model_training_data[\"rewards\"]\n",
        "        x_train, x_val, train_rewards, val_rewards = train_test_split(x, y, test_size=0.2)\n",
        "        del x, y\n",
        "        train_graphs = []\n",
        "        train_actions = []\n",
        "        for el in x_train:\n",
        "            train_graphs.append(el[0])\n",
        "            train_actions.append(el[1])\n",
        "        val_graphs = []\n",
        "        val_actions = []\n",
        "        for el in x_val:\n",
        "            val_graphs.append(el[0])\n",
        "            val_actions.append(el[1])\n",
        "        train_dataset = WormUpExamplesDataset(train_graphs, train_actions, train_rewards)\n",
        "        val_dataset = WormUpExamplesDataset(val_graphs, val_actions, val_rewards)\n",
        "        train_dataloader = train_dataset.get_dataloader(self.batch_size, shuffle=True)\n",
        "        val_dataloader = val_dataset.get_dataloader(self.batch_size, shuffle=True)\n",
        "        return train_dataloader, val_dataloader\n",
        "\n",
        "    def train_model(self):\n",
        "        print(\"begin training\")\n",
        "        train_dataloader, val_dataloader = self.prepare_data()\n",
        "        wndb.init(\n",
        "            # set the wandb project where this run will be logged\n",
        "            project=\"WormsWarmingUp\",\n",
        "\n",
        "            # track hyperparameters and run metadata\n",
        "            config={\n",
        "                \"learning_rate\": self.model_training_data.lr,\n",
        "                \"architecture\": str(self.model_training_data),\n",
        "                \"batch\": self.episode // self.episodes_for_batch\n",
        "            }\n",
        "        )\n",
        "        self.trainer.fit(self.model_training_data, train_dataloader, val_dataloader)\n",
        "        wndb.finish()\n",
        "        self.learning_model = IntelligentWorm.load_from_checkpoint(checkpoint_path=\"Model/worms_model.ckpt\")\n",
        "        print(\"finished training\")\n",
        ""
      ],
      "metadata": {
        "id": "_fvC294wOPdn"
      },
      "id": "_fvC294wOPdn",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **INITIALIZE MODEL, AGENT AND ENVIRONMENT**"
      ],
      "metadata": {
        "collapsed": false,
        "id": "3f6e6bda5945ae4"
      },
      "id": "3f6e6bda5945ae4"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "outputs": [],
      "source": [
        "\n",
        "# device = \"gpu\" if\n",
        "gnn_part = GraphNN(1,64,0,1,nn.ReLU())\n",
        "linear_part = LinearNN(64,1,128,2, nn.ReLU())\n",
        "\n",
        "worm_model = IntelligentWorm(linear_part, gnn_part)\n",
        "\n"
      ],
      "metadata": {
        "id": "c6922d2fab98a0dd"
      },
      "id": "c6922d2fab98a0dd"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: GPU available: False, used: False\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: False, used: False\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n"
          ]
        }
      ],
      "source": [
        "\n",
        "agent = WormsMasterAgent(worm_model,0.95,0.005,0.15)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f26f8e0665e69cf4",
        "outputId": "8f741918-fe1b-43a2-ed15-b6ca87fa2c45"
      },
      "id": "f26f8e0665e69cf4"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "outputs": [],
      "source": [
        "\n",
        "register(\n",
        "    id=\"worms_env\",\n",
        "    entry_point=\"worms_env:WormsEnv\",\n",
        "    max_episode_steps=300,\n",
        ")\n",
        "environment = gym.make('worms_env', env_file=\"Data/00-example.txt\", render_mode=\"human\")\n",
        "\n"
      ],
      "metadata": {
        "id": "3bda1e5e577c3a3"
      },
      "id": "3bda1e5e577c3a3"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **TRAINING**"
      ],
      "metadata": {
        "collapsed": false,
        "id": "dbda59ebd2b5a824"
      },
      "id": "dbda59ebd2b5a824"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "starting episode 0, epsilon = 0.95\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.available_movements to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.available_movements` for environment variables or `env.get_wrapper_attr('available_movements')` that will search the reminding wrappers.\u001b[0m\n",
            "  logger.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total reward = 24.0, actions list = [39, 40, 30, 31, 21, 20]\n",
            "starting episode 1, epsilon = 0.945\n",
            "total reward = 19.0, actions list = [21, 22, 23, 24, 0, 10]\n",
            "starting episode 2, epsilon = 0.94\n",
            "total reward = 29.0, actions list = [55, 54, 53, 43, 42, 52]\n",
            "starting episode 3, epsilon = 0.9349999999999999\n",
            "total reward = 25.0, actions list = [41, 31, 21, 0, 10, 20]\n",
            "starting episode 4, epsilon = 0.9299999999999999\n",
            "total reward = 34.0, actions list = [16, 17, 18, 8, 9, 10]\n",
            "starting episode 5, epsilon = 0.9249999999999999\n",
            "total reward = 28.0, actions list = [5, 15, 14, 24, 25, 35]\n",
            "starting episode 6, epsilon = 0.9199999999999999\n",
            "total reward = 39.0, actions list = [41, 51, 52, 42, 32, 22]\n",
            "starting episode 7, epsilon = 0.9149999999999999\n",
            "total reward = 29.0, actions list = [5, 15, 25, 26, 36, 35]\n",
            "starting episode 8, epsilon = 0.9099999999999999\n",
            "total reward = 28.0, actions list = [21, 31, 41, 51, 50, 40]\n",
            "starting episode 9, epsilon = 0.9049999999999999\n",
            "total reward = 20.0, actions list = [5, 4, 3, 13, 23, 33]\n",
            "starting episode 10, epsilon = 0.8999999999999999\n",
            "total reward = 27.0, actions list = [9, 2, 1, 0, 10, 11]\n",
            "starting episode 11, epsilon = 0.8949999999999999\n",
            "total reward = 27.0, actions list = [9, 10, 11, 21, 22, 12]\n",
            "starting episode 12, epsilon = 0.8899999999999999\n",
            "total reward = 18.0, actions list = [57, 47, 37, 27, 28, 18]\n",
            "starting episode 13, epsilon = 0.8849999999999999\n",
            "total reward = 24.0, actions list = [17, 7, 8, 0, 10, 11]\n",
            "starting episode 14, epsilon = 0.8799999999999999\n",
            "total reward = 18.0, actions list = [14, 13, 23, 24, 25, 26]\n",
            "starting episode 15, epsilon = 0.8749999999999999\n",
            "total reward = 18.0, actions list = [38, 37, 27, 28, 0, 1]\n",
            "starting episode 16, epsilon = 0.8699999999999999\n",
            "total reward = 26.0, actions list = [1, 2, 12, 11, 10, 9]\n",
            "starting episode 17, epsilon = 0.8649999999999999\n",
            "total reward = 30.0, actions list = [20, 19, 29, 30, 40, 39]\n",
            "starting episode 18, epsilon = 0.8599999999999999\n",
            "total reward = 30.0, actions list = [51, 50, 49, 48, 1, 2]\n",
            "starting episode 19, epsilon = 0.8549999999999999\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "PYDEV DEBUGGER WARNING:\n",
            "sys.settrace() should not be used when the debugger is being used.\n",
            "This may cause the debugger to stop working correctly.\n",
            "If this is needed, please check: \n",
            "http://pydev.blogspot.com/2007/06/why-cant-pydev-debugger-work-with.html\n",
            "to see how to restore the debug tracing back correctly.\n",
            "Call Location:\n",
            "  File \"/usr/lib/python3.10/bdb.py\", line 336, in set_trace\n",
            "    sys.settrace(self.trace_dispatch)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total reward = -999985.0, actions list = [1, 11, 10, 0]\n",
            "starting episode 20, epsilon = 0.8499999999999999\n",
            "begin training\n",
            "> \u001b[0;32m<ipython-input-14-2ce9ecbef734>\u001b[0m(93)\u001b[0;36mprepare_data\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m     91 \u001b[0;31m    \u001b[0;32mdef\u001b[0m \u001b[0mprepare_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m     92 \u001b[0;31m        \u001b[0mbreakpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m---> 93 \u001b[0;31m        \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"preparing data to train\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m     94 \u001b[0;31m        \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_training_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"observations\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_training_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"actions\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m     95 \u001b[0;31m        \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_training_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"rewards\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\n",
            "ipdb> n\n",
            "preparing data to train\n",
            "> \u001b[0;32m<ipython-input-14-2ce9ecbef734>\u001b[0m(94)\u001b[0;36mprepare_data\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m     92 \u001b[0;31m        \u001b[0mbreakpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m     93 \u001b[0;31m        \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"preparing data to train\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m---> 94 \u001b[0;31m        \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_training_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"observations\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_training_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"actions\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m     95 \u001b[0;31m        \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_training_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"rewards\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m     96 \u001b[0;31m        \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_rewards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_rewards\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\n",
            "ipdb> n\n",
            "> \u001b[0;32m<ipython-input-14-2ce9ecbef734>\u001b[0m(95)\u001b[0;36mprepare_data\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m     93 \u001b[0;31m        \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"preparing data to train\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m     94 \u001b[0;31m        \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_training_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"observations\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_training_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"actions\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m---> 95 \u001b[0;31m        \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_training_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"rewards\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m     96 \u001b[0;31m        \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_rewards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_rewards\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m     97 \u001b[0;31m        \u001b[0;32mdel\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\n",
            "ipdb> x\n",
            "<zip object at 0x7e087bb42380>\n",
            "ipdb> list(x)\n",
            "*** Error in argument: '(x)'\n",
            "ipdb> print(x)\n",
            "<zip object at 0x7e087bb42380>\n",
            "ipdb> list(x)\n",
            "*** Error in argument: '(x)'\n",
            "ipdb> self.model_training_data['observations']\n",
            "[Data(x=[60], edge_index=[2, 208]), Data(x=[60], edge_index=[2, 208]), Data(x=[60], edge_index=[2, 208]), Data(x=[60], edge_index=[2, 208]), Data(x=[60], edge_index=[2, 208]), Data(x=[60], edge_index=[2, 208]), Data(x=[60], edge_index=[2, 208]), Data(x=[60], edge_index=[2, 208]), Data(x=[60], edge_index=[2, 208]), Data(x=[60], edge_index=[2, 208]), Data(x=[60], edge_index=[2, 208]), Data(x=[60], edge_index=[2, 208]), Data(x=[60], edge_index=[2, 208]), Data(x=[60], edge_index=[2, 208]), Data(x=[60], edge_index=[2, 208]), Data(x=[60], edge_index=[2, 208]), Data(x=[60], edge_index=[2, 208]), Data(x=[60], edge_index=[2, 208]), Data(x=[60], edge_index=[2, 208]), Data(x=[60], edge_index=[2, 208]), Data(x=[60], edge_index=[2, 208]), Data(x=[60], edge_index=[2, 208]), Data(x=[60], edge_index=[2, 208]), Data(x=[60], edge_index=[2, 208]), Data(x=[60], edge_index=[2, 208]), Data(x=[60], edge_index=[2, 208]), Data(x=[60], edge_index=[2, 208]), Data(x=[60], edge_index=[2, 208]), Data(x=[60], edge_index=[2, 208]), Data(x=[60], edge_index=[2, 208]), Data(x=[60], edge_index=[2, 208]), Data(x=[60], edge_index=[2, 208]), Data(x=[60], edge_index=[2, 208]), Data(x=[60], edge_index=[2, 208]), Data(x=[60], edge_index=[2, 208]), Data(x=[60], edge_index=[2, 208]), Data(x=[60], edge_index=[2, 208]), Data(x=[60], edge_index=[2, 208]), Data(x=[60], edge_index=[2, 208]), Data(x=[60], edge_index=[2, 208]), Data(x=[60], edge_index=[2, 208]), Data(x=[60], edge_index=[2, 208]), Data(x=[60], edge_index=[2, 208]), Data(x=[60], edge_index=[2, 208]), Data(x=[60], edge_index=[2, 208]), Data(x=[60], edge_index=[2, 208]), Data(x=[60], edge_index=[2, 208]), Data(x=[60], edge_index=[2, 208]), Data(x=[60], edge_index=[2, 208]), Data(x=[60], edge_index=[2, 208]), Data(x=[60], edge_index=[2, 208]), Data(x=[60], edge_index=[2, 208]), Data(x=[60], edge_index=[2, 208]), Data(x=[60], edge_index=[2, 208]), Data(x=[60], edge_index=[2, 208]), Data(x=[60], edge_index=[2, 208]), Data(x=[60], edge_index=[2, 208]), Data(x=[60], edge_index=[2, 208]), Data(x=[60], edge_index=[2, 208]), Data(x=[60], edge_index=[2, 208]), Data(x=[60], edge_index=[2, 208]), Data(x=[60], edge_index=[2, 208]), Data(x=[60], edge_index=[2, 208]), Data(x=[60], edge_index=[2, 208]), Data(x=[60], edge_index=[2, 208]), Data(x=[60], edge_index=[2, 208]), Data(x=[60], edge_index=[2, 208]), Data(x=[60], edge_index=[2, 208]), Data(x=[60], edge_index=[2, 208]), Data(x=[60], edge_index=[2, 208]), Data(x=[60], edge_index=[2, 208]), Data(x=[60], edge_index=[2, 208]), Data(x=[60], edge_index=[2, 208]), Data(x=[60], edge_index=[2, 208]), Data(x=[60], edge_index=[2, 208]), Data(x=[60], edge_index=[2, 208]), Data(x=[60], edge_index=[2, 208]), Data(x=[60], edge_index=[2, 208]), Data(x=[60], edge_index=[2, 208]), Data(x=[60], edge_index=[2, 208]), Data(x=[60], edge_index=[2, 208]), Data(x=[60], edge_index=[2, 208]), Data(x=[60], edge_index=[2, 208]), Data(x=[60], edge_index=[2, 208]), Data(x=[60], edge_index=[2, 208]), Data(x=[60], edge_index=[2, 208]), Data(x=[60], edge_index=[2, 208]), Data(x=[60], edge_index=[2, 208]), Data(x=[60], edge_index=[2, 208]), Data(x=[60], edge_index=[2, 208]), Data(x=[60], edge_index=[2, 208]), Data(x=[60], edge_index=[2, 208]), Data(x=[60], edge_index=[2, 208]), Data(x=[60], edge_index=[2, 208]), Data(x=[60], edge_index=[2, 208]), Data(x=[60], edge_index=[2, 208]), Data(x=[60], edge_index=[2, 208]), Data(x=[60], edge_index=[2, 208]), Data(x=[60], edge_index=[2, 208]), Data(x=[60], edge_index=[2, 208]), Data(x=[60], edge_index=[2, 208]), Data(x=[60], edge_index=[2, 208]), Data(x=[60], edge_index=[2, 208]), Data(x=[60], edge_index=[2, 208]), Data(x=[60], edge_index=[2, 208]), Data(x=[60], edge_index=[2, 208]), Data(x=[60], edge_index=[2, 208]), Data(x=[60], edge_index=[2, 208]), Data(x=[60], edge_index=[2, 208]), Data(x=[60], edge_index=[2, 208]), Data(x=[60], edge_index=[2, 208]), Data(x=[60], edge_index=[2, 208]), Data(x=[60], edge_index=[2, 208]), Data(x=[60], edge_index=[2, 208]), Data(x=[60], edge_index=[2, 208]), Data(x=[60], edge_index=[2, 208]), Data(x=[60], edge_index=[2, 208]), Data(x=[60], edge_index=[2, 208])]\n",
            "ipdb> self.model_training_data['actions']\n",
            "[39, 40, 30, 31, 21, 20, 21, 22, 23, 24, 0, 10, 55, 54, 53, 43, 42, 52, 41, 31, 21, 0, 10, 20, 16, 17, 18, 8, 9, 10, 5, 15, 14, 24, 25, 35, 41, 51, 52, 42, 32, 22, 5, 15, 25, 26, 36, 35, 21, 31, 41, 51, 50, 40, 5, 4, 3, 13, 23, 33, 9, 2, 1, 0, 10, 11, 9, 10, 11, 21, 22, 12, 57, 47, 37, 27, 28, 18, 17, 7, 8, 0, 10, 11, 14, 13, 23, 24, 25, 26, 38, 37, 27, 28, 0, 1, 1, 2, 12, 11, 10, 9, 20, 19, 29, 30, 40, 39, 51, 50, 49, 48, 1, 2, 1, 11, 10, 0]\n",
            "ipdb> n\n",
            "> \u001b[0;32m<ipython-input-14-2ce9ecbef734>\u001b[0m(96)\u001b[0;36mprepare_data\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m     94 \u001b[0;31m        \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_training_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"observations\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_training_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"actions\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m     95 \u001b[0;31m        \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_training_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"rewards\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m---> 96 \u001b[0;31m        \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_rewards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_rewards\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m     97 \u001b[0;31m        \u001b[0;32mdel\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m     98 \u001b[0;31m        \u001b[0mtrain_graphs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\n",
            "ipdb> train_test_split(x, y, test_size=0.2)\n",
            "*** TypeError: Singleton array array(<zip object at 0x7e087bb42380>, dtype=object) cannot be considered a valid collection.\n",
            "ipdb> train_test_split(list(x), y, test_size=0.2)\n",
            "[[(Data(x=[60], edge_index=[2, 208]), 35), (Data(x=[60], edge_index=[2, 208]), 21), (Data(x=[60], edge_index=[2, 208]), 11), (Data(x=[60], edge_index=[2, 208]), 38), (Data(x=[60], edge_index=[2, 208]), 37), (Data(x=[60], edge_index=[2, 208]), 9), (Data(x=[60], edge_index=[2, 208]), 13), (Data(x=[60], edge_index=[2, 208]), 41), (Data(x=[60], edge_index=[2, 208]), 47), (Data(x=[60], edge_index=[2, 208]), 22), (Data(x=[60], edge_index=[2, 208]), 23), (Data(x=[60], edge_index=[2, 208]), 36), (Data(x=[60], edge_index=[2, 208]), 54), (Data(x=[60], edge_index=[2, 208]), 25), (Data(x=[60], edge_index=[2, 208]), 27), (Data(x=[60], edge_index=[2, 208]), 11), (Data(x=[60], edge_index=[2, 208]), 52), (Data(x=[60], edge_index=[2, 208]), 13), (Data(x=[60], edge_index=[2, 208]), 23), (Data(x=[60], edge_index=[2, 208]), 15), (Data(x=[60], edge_index=[2, 208]), 21), (Data(x=[60], edge_index=[2, 208]), 29), (Data(x=[60], edge_index=[2, 208]), 14), (Data(x=[60], edge_index=[2, 208]), 40), (Data(x=[60], edge_index=[2, 208]), 18), (Data(x=[60], edge_index=[2, 208]), 49), (Data(x=[60], edge_index=[2, 208]), 1), (Data(x=[60], edge_index=[2, 208]), 10), (Data(x=[60], edge_index=[2, 208]), 12), (Data(x=[60], edge_index=[2, 208]), 21), (Data(x=[60], edge_index=[2, 208]), 25), (Data(x=[60], edge_index=[2, 208]), 51), (Data(x=[60], edge_index=[2, 208]), 50), (Data(x=[60], edge_index=[2, 208]), 32), (Data(x=[60], edge_index=[2, 208]), 11), (Data(x=[60], edge_index=[2, 208]), 42), (Data(x=[60], edge_index=[2, 208]), 51), (Data(x=[60], edge_index=[2, 208]), 10), (Data(x=[60], edge_index=[2, 208]), 31), (Data(x=[60], edge_index=[2, 208]), 9), (Data(x=[60], edge_index=[2, 208]), 31), (Data(x=[60], edge_index=[2, 208]), 5), (Data(x=[60], edge_index=[2, 208]), 8), (Data(x=[60], edge_index=[2, 208]), 20), (Data(x=[60], edge_index=[2, 208]), 39), (Data(x=[60], edge_index=[2, 208]), 2), (Data(x=[60], edge_index=[2, 208]), 15), (Data(x=[60], edge_index=[2, 208]), 10), (Data(x=[60], edge_index=[2, 208]), 39), (Data(x=[60], edge_index=[2, 208]), 48), (Data(x=[60], edge_index=[2, 208]), 50), (Data(x=[60], edge_index=[2, 208]), 10), (Data(x=[60], edge_index=[2, 208]), 25), (Data(x=[60], edge_index=[2, 208]), 2), (Data(x=[60], edge_index=[2, 208]), 0), (Data(x=[60], edge_index=[2, 208]), 8), (Data(x=[60], edge_index=[2, 208]), 24), (Data(x=[60], edge_index=[2, 208]), 28), (Data(x=[60], edge_index=[2, 208]), 9), (Data(x=[60], edge_index=[2, 208]), 3), (Data(x=[60], edge_index=[2, 208]), 0), (Data(x=[60], edge_index=[2, 208]), 0), (Data(x=[60], edge_index=[2, 208]), 18), (Data(x=[60], edge_index=[2, 208]), 52), (Data(x=[60], edge_index=[2, 208]), 28), (Data(x=[60], edge_index=[2, 208]), 41), (Data(x=[60], edge_index=[2, 208]), 10), (Data(x=[60], edge_index=[2, 208]), 24), (Data(x=[60], edge_index=[2, 208]), 2), (Data(x=[60], edge_index=[2, 208]), 4), (Data(x=[60], edge_index=[2, 208]), 0), (Data(x=[60], edge_index=[2, 208]), 0), (Data(x=[60], edge_index=[2, 208]), 1), (Data(x=[60], edge_index=[2, 208]), 1), (Data(x=[60], edge_index=[2, 208]), 40), (Data(x=[60], edge_index=[2, 208]), 53), (Data(x=[60], edge_index=[2, 208]), 14), (Data(x=[60], edge_index=[2, 208]), 9), (Data(x=[60], edge_index=[2, 208]), 35), (Data(x=[60], edge_index=[2, 208]), 21), (Data(x=[60], edge_index=[2, 208]), 23), (Data(x=[60], edge_index=[2, 208]), 26), (Data(x=[60], edge_index=[2, 208]), 30), (Data(x=[60], edge_index=[2, 208]), 21), (Data(x=[60], edge_index=[2, 208]), 10), (Data(x=[60], edge_index=[2, 208]), 41), (Data(x=[60], edge_index=[2, 208]), 0), (Data(x=[60], edge_index=[2, 208]), 37), (Data(x=[60], edge_index=[2, 208]), 40), (Data(x=[60], edge_index=[2, 208]), 7), (Data(x=[60], edge_index=[2, 208]), 22), (Data(x=[60], edge_index=[2, 208]), 24), (Data(x=[60], edge_index=[2, 208]), 11), (Data(x=[60], edge_index=[2, 208]), 55)], [(Data(x=[60], edge_index=[2, 208]), 20), (Data(x=[60], edge_index=[2, 208]), 20), (Data(x=[60], edge_index=[2, 208]), 26), (Data(x=[60], edge_index=[2, 208]), 17), (Data(x=[60], edge_index=[2, 208]), 43), (Data(x=[60], edge_index=[2, 208]), 42), (Data(x=[60], edge_index=[2, 208]), 17), (Data(x=[60], edge_index=[2, 208]), 11), (Data(x=[60], edge_index=[2, 208]), 22), (Data(x=[60], edge_index=[2, 208]), 5), (Data(x=[60], edge_index=[2, 208]), 5), (Data(x=[60], edge_index=[2, 208]), 27), (Data(x=[60], edge_index=[2, 208]), 19), (Data(x=[60], edge_index=[2, 208]), 10), (Data(x=[60], edge_index=[2, 208]), 51), (Data(x=[60], edge_index=[2, 208]), 10), (Data(x=[60], edge_index=[2, 208]), 16), (Data(x=[60], edge_index=[2, 208]), 33), (Data(x=[60], edge_index=[2, 208]), 30), (Data(x=[60], edge_index=[2, 208]), 1), (Data(x=[60], edge_index=[2, 208]), 31), (Data(x=[60], edge_index=[2, 208]), 1), (Data(x=[60], edge_index=[2, 208]), 57), (Data(x=[60], edge_index=[2, 208]), 12)], [3.0, 19.0, 13.0, 18.0, 14.0, 14.0, 13.0, 39.0, 14.0, 5.0, 10.0, 8.0, 23.0, 18.0, 11.0, 18.0, 26.0, 3.0, 3.0, 20.0, 28.0, 19.0, 18.0, 18.0, 22.0, 20.0, 5.0, 6.0, 0.0, 7.0, 10.0, 30.0, 6.0, 11.0, -999990.0, 18.0, 33.0, 14.0, 24.0, 8.0, 12.0, 20.0, 20.0, 3.0, 24.0, 3.0, 21.0, 6.0, 6.0, 13.0, 23.0, 10.0, 9.0, 19.0, 11.0, 17.0, 12.0, 7.0, 27.0, 9.0, 11.0, 10.0, 2.0, 8.0, 11.0, 25.0, 10.0, 13.0, 21.0, 12.0, 6.0, 7.0, -999985.0, 16.0, 3.0, 20.0, 17.0, 27.0, 3.0, 9.0, 13.0, 4.0, 15.0, 14.0, 19.0, 19.0, -1000000.0, 10.0, 9.0, 19.0, 15.0, 10.0, 4.0, 29.0], [30.0, 3.0, 12.0, 24.0, 15.0, 15.0, 27.0, 4.0, 5.0, 29.0, 28.0, 7.0, 27.0, 9.0, 13.0, -999994.0, 34.0, 3.0, 12.0, 26.0, 19.0, 8.0, 18.0, 18.0]]\n",
            "ipdb> q\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "PYDEV DEBUGGER WARNING:\n",
            "sys.settrace() should not be used when the debugger is being used.\n",
            "This may cause the debugger to stop working correctly.\n",
            "If this is needed, please check: \n",
            "http://pydev.blogspot.com/2007/06/why-cant-pydev-debugger-work-with.html\n",
            "to see how to restore the debug tracing back correctly.\n",
            "Call Location:\n",
            "  File \"/usr/lib/python3.10/bdb.py\", line 361, in set_quit\n",
            "    sys.settrace(None)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "MAX_EPISODES = 200\n",
        "\n",
        "done = False\n",
        "obs, info = environment.reset()\n",
        "print(f\"starting episode {agent.episode}, epsilon = {agent.epsilon}\")\n",
        "# play one episode\n",
        "while agent.episode < MAX_EPISODES:\n",
        "\n",
        "    action = agent.get_action(info, environment.available_movements)\n",
        "    obs, reward, terminated, truncated, info = environment.step(action)\n",
        "    agent.update(info, action, reward, terminated)\n",
        "\n",
        "    if terminated:\n",
        "        obs, info = environment.reset()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9996703fbac80ef",
        "outputId": "55e1d12b-c653-4971-f3ef-9d6015fed0a2"
      },
      "id": "a9996703fbac80ef"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}