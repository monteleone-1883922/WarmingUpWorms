{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# **SETUP**"
   ],
   "metadata": {
    "id": "JlXSQpAMME6g"
   },
   "id": "JlXSQpAMME6g"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "id": "initial_id"
   },
   "outputs": [],
   "source": [
    "\n",
    "!pip install torch-geometric lightning wandb gymnasium\n",
    "!pip install -U scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch_geometric.data import Data\n",
    "import lightning as L\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import wandb as wndb\n",
    "from torch_geometric.nn import GATConv\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, root_mean_squared_error\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "import gymnasium as gym\n",
    "from gymnasium.envs.registration import register"
   ],
   "metadata": {
    "id": "TBf6OzRISHY3"
   },
   "id": "TBf6OzRISHY3",
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **MODEL AND RELATED STUFF**"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4bf1f40cd3ec9c0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class GreedyWorm(nn.Module):\n",
    "  \n",
    "  def __init__(self):\n",
    "    super(GreedyWorm, self).__init__()\n",
    "  \n",
    "  def forward(self, data):\n",
    "    graphs, positions = data\n",
    "    return [graphs[i].x[positions[i]] for i in range(len(positions))]\n",
    "    "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2a703591e88d0fae"
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "class WormUpExamplesDataset(Dataset):\n",
    "\n",
    "  def __init__(self, graphs: list[Data], actions: list[int], rewards: list[int]):\n",
    "    self.data = zip(graphs, actions, rewards)\n",
    "\n",
    "\n",
    "  def __getitem__(self, idx: int):\n",
    "    return self.data[idx]\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.data)\n",
    "\n",
    "  def collate(self,data: list):\n",
    "    graphs = []\n",
    "    actions = []\n",
    "    rewards = []\n",
    "    for el in data:\n",
    "      graphs.append(el[0])\n",
    "      actions.append(el[1])\n",
    "      rewards.append(el[2])\n",
    "    return graphs,actions, rewards\n",
    "\n",
    "  def get_dataloader(self, batch_size: int, shuffle: bool = False):\n",
    "    return DataLoader(self, batch_size=batch_size, shuffle=shuffle, collate_fn=self.collate)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "id": "RGjiW4gISNyY"
   },
   "id": "RGjiW4gISNyY",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class GraphNN(nn.Module):\n",
    "\n",
    "  def __init__(self,in_size, out_size, h_size, deep,activation,device=\"cpu\"):\n",
    "    super(GraphNN, self).__init__()\n",
    "    self.activation = activation\n",
    "    if deep == 1:\n",
    "      self.layers = [GATConv(in_size,out_size)]#.to(device)]\n",
    "    else:\n",
    "      self.layers = [GATConv(in_size,h_size)]#.to(device)]\n",
    "      for _ in range(deep-2):\n",
    "        self.layers.append(GATConv(h_size,h_size))#.to(device))\n",
    "      self.layers.append(GATConv(h_size,out_size))#.to(device))\n",
    "\n",
    "\n",
    "  def forward(self,data):\n",
    "    edge_index = data.edge_index\n",
    "    edge_attr = data.edge_attr\n",
    "    x = data.x\n",
    "    for layer in self.layers[:-1]:\n",
    "      x = self.activation(layer(x, edge_index, edge_attr))\n",
    "\n",
    "    return self.layers[-1](x, edge_index, edge_attr)\n",
    "\n"
   ],
   "metadata": {
    "id": "a7077f94db9f1513"
   },
   "id": "a7077f94db9f1513"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class LinearNN(nn.Module):\n",
    "  def __init__(self,in_size, out_size, h_size, deep,activation):\n",
    "    super(LinearNN, self).__init__()\n",
    "    if deep == 1:\n",
    "      layers = [nn.Linear(in_size,out_size), activation]\n",
    "    else:\n",
    "      layers = [nn.Linear(in_size,h_size), activation]\n",
    "      for _ in range(deep-2):\n",
    "        layers.append(nn.Linear(h_size,h_size))\n",
    "        layers.append(activation)\n",
    "      layers.append(nn.Linear(h_size,out_size))\n",
    "    self.linear = nn.Sequential(*layers)\n",
    "\n",
    "  def forward(self,data):\n",
    "    return self.linear(data)"
   ],
   "metadata": {
    "id": "2e04dccdc0f056e0"
   },
   "id": "2e04dccdc0f056e0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "class IntelligentWorm(L.LightningModule):\n",
    "\n",
    "    def __int__(self, linear: nn.Module, gnn: nn.Module, lr: float = 1e-3):\n",
    "        super(IntelligentWorm, self).__init__()\n",
    "        self.encoder = gnn\n",
    "        self.decoder = linear\n",
    "        self.loss = nn.MSELoss()\n",
    "        self.validation_predictions = []\n",
    "        self.validation_targets = []\n",
    "        self.validation_loss = []\n",
    "        self.train_loss = []\n",
    "        self.best_val_loss = 100000000\n",
    "        self.best_mae = 100000000\n",
    "        self.best_rmse = 1000000000\n",
    "        self.best_r2 = -1\n",
    "        self.best_model = 0\n",
    "        self.lr = lr\n",
    "\n",
    "    def update_best_stats(self, val_loss, mae, rmse, r2):\n",
    "        self.best_val_loss = val_loss\n",
    "        self.best_mae = mae\n",
    "        self.best_rmse = rmse\n",
    "        self.best_r2 = r2\n",
    "            \n",
    "\n",
    "    def forward(self, data):\n",
    "        actions = data[1]\n",
    "        graphs = data[0]\n",
    "        embeddings = []\n",
    "        for i in range(len(graphs)):\n",
    "            g = graphs[i]\n",
    "            x = self.encoder(g.x, g.edge_index)\n",
    "            embeddings.append(x[actions[i]])\n",
    "        embeddings = torch.tensor(embeddings, dtype=torch.float)\n",
    "        return self.decoder(embeddings)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        graphs, actions, rewards = batch\n",
    "        predictions = self.forward((graphs, actions))\n",
    "        train_loss = self.loss(predictions, rewards)\n",
    "        self.train_loss.append(train_loss)\n",
    "\n",
    "        return train_loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        graphs, actions, rewards = batch\n",
    "        self.validation_targets.append(rewards)\n",
    "        predictions = self.forward((graphs, actions))\n",
    "        validation_loss = self.loss(predictions, rewards)\n",
    "        self.validation_predictions.append(predictions)\n",
    "        self.validation_loss.append(validation_loss)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "        return optimizer\n",
    "\n"
   ],
   "metadata": {
    "id": "19fe1a895b6ecda6"
   },
   "id": "19fe1a895b6ecda6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class WormCallback(L.Callback):\n",
    "\n",
    "  def on_train_epoch_end(self, trainer, pl_module):\n",
    "\n",
    "      epoch_mean = float(torch.stack(pl_module.train_loss).mean())\n",
    "      print(\"training_epoch_mean loss = \", epoch_mean)\n",
    "      # free up the memory\n",
    "      pl_module.train_loss.clear()\n",
    "      try:\n",
    "        wndb.log({\"train_loss\": epoch_mean})\n",
    "      except:\n",
    "        pass\n",
    "\n",
    "\n",
    "  def on_validation_epoch_end(self,trainer, pl_module: IntelligentWorm):\n",
    "    r2 = r2_score(pl_module.validation_predictions, pl_module.validation_targets)\n",
    "    mae = mean_absolute_error(pl_module.validation_predictions, pl_module.validation_targets)\n",
    "    rmse = root_mean_squared_error(pl_module.validation_predictions, pl_module.validation_targets)\n",
    "    pl_module.validation_loss.clear()\n",
    "    pl_module.validation_predictions.clear()\n",
    "    pl_module.validation_targets.clear()\n",
    "\n",
    "    mean_loss = float(torch.stack(pl_module.validation_loss).mean())\n",
    "\n",
    "    print(\"val_loss = \", mean_loss)\n",
    "    print(\"mean_absolute_error = \", mae)\n",
    "    print(\"root_mean_squared_error = \", rmse)\n",
    "    print(\"r2 = \", r2)\n",
    "    count = 0\n",
    "    count += 1 if mean_loss < pl_module.best_val_loss else 0\n",
    "    count += 1 if mae < pl_module.best_mae else 0\n",
    "    count += 1 if rmse < pl_module.best_rmse else 0\n",
    "    count += 1 if r2 > pl_module.best_r2 else 0\n",
    "    if count >= 3 or count == 2 and mean_loss < pl_module.best_val_loss:\n",
    "        pl_module.update_best_stats(mean_loss,mae,rmse,r2)\n",
    "        pl_module.best_model -= 1\n",
    "        pl_module.log(\"best_model\", pl_module.best_model)\n",
    "    else:\n",
    "        pl_module.log(\"best_model\", pl_module.best_model + 1)\n",
    "    \n",
    "    try:\n",
    "      wndb.log({\"val_loss\": mean_loss, \"mean_absolute_error\": mae, \"root_mean_squared_error\": rmse, \"r2\": r2 })\n",
    "    except:\n",
    "      pass\n",
    "\n"
   ],
   "metadata": {
    "id": "dcd567e72bf3219b"
   },
   "id": "dcd567e72bf3219b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **AGENT**"
   ],
   "metadata": {
    "id": "zeEN5X3hOH3D"
   },
   "id": "zeEN5X3hOH3D"
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "class WormsMasterAgent:\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            model,\n",
    "            initial_epsilon: float,\n",
    "            epsilon_decay: float,\n",
    "            final_epsilon: float,\n",
    "            learning_rate: float = 1,\n",
    "            discount_factor: float = 0.95,\n",
    "            decay_after: int = 1,\n",
    "            #trainer params\n",
    "            batch_size: int = 32,\n",
    "            episodes_for_batch: int = 20,\n",
    "            trainer_deterministic: bool = True,\n",
    "            trainer_max_epochs: int = 20,\n",
    "            trainer_accelerator: str = \"cpu\"\n",
    "\n",
    "    ):\n",
    "        self.batch_size = batch_size\n",
    "        self.episodes_for_batch = episodes_for_batch\n",
    "        self.episode = 0\n",
    "        self.learning_model = model\n",
    "        self.model = GreedyWorm()\n",
    "        self.lr = learning_rate\n",
    "        self.discount_factor = discount_factor\n",
    "        self.epsilon = initial_epsilon\n",
    "        self.epsilon_decay = epsilon_decay\n",
    "        self.final_epsilon = final_epsilon\n",
    "        self.decay_after = decay_after\n",
    "        self.checkpoint_callback = ModelCheckpoint(dirpath=\"Model/\", filename=\"worms_model.ckpt\", save_top_k=1,\n",
    "                                                   mode='min', monitor='best_model')\n",
    "        self.worm_callback = WormCallback()\n",
    "        self.early_stopping_callback = EarlyStopping(monitor='best_model', mode='min', patience=3)\n",
    "        self.trainer = L.Trainer(deterministic=trainer_deterministic,\n",
    "                                 max_epochs=trainer_max_epochs, accelerator=trainer_accelerator,\n",
    "                                 callbacks=[self.checkpoint_callback, self.worm_callback, self.early_stopping_callback])\n",
    "        self.actual_rewards = np.array([])\n",
    "        self.actual_observations = []\n",
    "        self.actual_actions = []\n",
    "        self.model_training_data = {\n",
    "            \"actions\": [],\n",
    "            \"observations\": [],\n",
    "            \"rewards\": []\n",
    "        }\n",
    "\n",
    "    def get_action(self, observation, available_actions: list[int]) -> int:\n",
    "        graph = observation[\"field\"]\n",
    "        snakes = observation[\"snakes\"]\n",
    "        np.append(self.actual_rewards, 0)\n",
    "        # with probability epsilon return a random action to explore the environment\n",
    "        if np.random.random() < self.epsilon:\n",
    "            i = np.random.randint(0, high=len(available_actions))\n",
    "            return available_actions[i]\n",
    "\n",
    "        # with probability (1 - epsilon) act greedily (exploit)\n",
    "        else:\n",
    "            self.model.eval()\n",
    "            with torch.no_grad():\n",
    "                return np.argmax(self.model([graph] * len(available_actions), available_actions))\n",
    "\n",
    "    def update(self, observation, action: int, reward: int, terminated: bool):\n",
    "        graph = observation[\"field\"]\n",
    "        snakes = observation[\"snakes\"]\n",
    "        self.actual_observations.append(graph)\n",
    "        self.actual_actions.append(action)\n",
    "        self.actual_rewards += self.lr * reward\n",
    "\n",
    "        if terminated:\n",
    "            self.episode += 1\n",
    "            self.model_training_data[\"actions\"] += self.actual_actions.copy()\n",
    "            self.actual_actions = []\n",
    "            self.model_training_data[\"observations\"] += self.actual_observations.copy()\n",
    "            self.actual_observations = []\n",
    "            self.model_training_data[\"rewards\"] += self.actual_rewards.tolist()\n",
    "            self.actual_rewards = np.array([])\n",
    "            if self.episode % self.decay_after == 0:\n",
    "                self.decay_epsilon()\n",
    "\n",
    "            if self.episode % self.episodes_for_batch == 0:\n",
    "                self.train_model()\n",
    "                self.model = self.learning_model\n",
    "\n",
    "    def decay_epsilon(self):\n",
    "        self.epsilon = max(self.final_epsilon, self.epsilon - self.epsilon_decay)\n",
    "\n",
    "    def prepare_data(self):\n",
    "        x = zip(self.model_training_data[\"observations\"], self.model_training_data[\"actions\"])\n",
    "        y = self.model_training_data[\"rewards\"]\n",
    "        x_train, x_val, train_rewards, val_rewards = train_test_split(x, y, test_size=0.2)\n",
    "        del x, y\n",
    "        train_graphs = []\n",
    "        train_actions = []\n",
    "        for el in x_train:\n",
    "            train_graphs.append(el[0])\n",
    "            train_actions.append(el[1])\n",
    "        val_graphs = []\n",
    "        val_actions = []\n",
    "        for el in x_val:\n",
    "            val_graphs.append(el[0])\n",
    "            val_actions.append(el[1])\n",
    "        train_dataset = WormUpExamplesDataset(train_graphs, train_actions, train_rewards)\n",
    "        val_dataset = WormUpExamplesDataset(val_graphs, val_actions, val_rewards)\n",
    "        train_dataloader = train_dataset.get_dataloader(self.batch_size, shuffle=True)\n",
    "        val_dataloader = val_dataset.get_dataloader(self.batch_size, shuffle=True)\n",
    "        return train_dataloader, val_dataloader\n",
    "\n",
    "    def train_model(self):\n",
    "        train_dataloader, val_dataloader = self.prepare_data()\n",
    "        wndb.init(\n",
    "            # set the wandb project where this run will be logged\n",
    "            project=\"WormsWarmingUp\",\n",
    "            \n",
    "            # track hyperparameters and run metadata\n",
    "            config={\n",
    "            \"learning_rate\": self.model_training_data.lr,\n",
    "            \"architecture\": str(self.model_training_data),\n",
    "            \"batch\": self.episode // self.episodes_for_batch\n",
    "            }\n",
    "        )\n",
    "        self.trainer.fit(self.model_training_data, train_dataloader, val_dataloader)\n",
    "        wndb.finish()\n",
    "        self.learning_model = IntelligentWorm.load_from_checkpoint(checkpoint_path=\"Model/worms_model.ckpt\")\n",
    "        "
   ],
   "metadata": {
    "id": "_fvC294wOPdn"
   },
   "id": "_fvC294wOPdn",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **INITIALIZE MODEL, AGENT AND ENVIRONMENT**"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3f6e6bda5945ae4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# device = \"gpu\" if \n",
    "gnn_part = GraphNN(1,64,0,1,nn.ReLU())\n",
    "linear_part = LinearNN(64,1,128,2, nn.ReLU())\n",
    "\n",
    "worm_model = IntelligentWorm(linear_part, gnn_part)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c6922d2fab98a0dd"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "agent = WormsMasterAgent(worm_model,0.95,0.005,0.15)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f26f8e0665e69cf4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "register(\n",
    "          id=\"worms_env\",\n",
    "          entry_point=\"worms_env:WormsEnv\",\n",
    "          max_episode_steps=300,\n",
    "     )\n",
    "environment = gym.make('worms_env',  env_file=\"Data/00-example.txt\", render_mode=\"human\")\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3bda1e5e577c3a3"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "provenance": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
